{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "### **Libraries**"
      ],
      "metadata": {
        "id": "Y3_d5yx-9Ii3"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Jb6ziTT1de1J"
      },
      "outputs": [],
      "source": [
        "import math\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt \n",
        "from time import time"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf"
      ],
      "metadata": {
        "id": "hJ1_oehZDI6q"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **Global Variables**"
      ],
      "metadata": {
        "id": "OOJL-ChgC884"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### **Physics Related Constants**"
      ],
      "metadata": {
        "id": "wdwJzeyGXbyK"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "alpha = 0.0801 * 1e6\n",
        "k     = 0.05 * 1e3\n",
        "v     = 10.0 * 1e-3\n",
        "m     = 0.6\n",
        "n     = 0.4\n",
        "Q     = 1652.4\n",
        "a_f   = 1.002 * 1e-3\n",
        "a_r   = 3.34 * 1e-3\n",
        "b     = 1.67 * 1e-3\n",
        "c     = 1.67 * 1e-3\n",
        "h     = 20e-6 * 1e6\n",
        "T_0   = 293.15\n",
        "T_MAX = 1723"
      ],
      "metadata": {
        "id": "yGw3in-gC8J5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### **PINN Related**"
      ],
      "metadata": {
        "id": "yInERkJaXexe"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "SEED       = 42\n",
        "BATCH_SIZE = 256\n",
        "DEBUG      = False"
      ],
      "metadata": {
        "id": "epnagLzrQDoo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\"\"\"\n",
        "Strings that can be used as keys in inputParams dict\n",
        "\"\"\"\n",
        "\n",
        "INPUT_LAYER_DIM         = \"inputLayerDim\"\n",
        "OUTPUT_LAYER_DIM        = \"outputLayerDim\"\n",
        "HIDDEN_LAYERS_DIM       = \"hiddenLayersDim\"\n",
        "ANALYTICAL_SOLUTION     = \"analyticalSolution\"\n",
        "RESIDUAL                = \"residual\"\n",
        "EVALUATE_RESIDUAL       = \"evaluateResidual\"\n",
        "EVALUATE_BOUNDARY_EQN_1 = \"evaluateBoundaryEqn_1\"\n",
        "EVALUATE_BOUNDARY_EQN_2 = \"evaluateBoundaryEqn_2\"\n",
        "EVALUATE_BOUNDARY_EQN_3 = \"evaluateBoundaryEqn_3\"\n",
        "LEARNING_RATE           = \"learningRate\"\n",
        "EPOCHS                  = \"epochs\"\n",
        "PRINT_INTERVAL          = \"print_interval\"\n",
        "TRAINING_POINTS         = \"trainingPoints\"\n",
        "TRAINING_LABELS         = \"trainingLabels\"\n",
        "TEST_POINTS             = \"testPoints\"\n",
        "TEST_LABELS             = \"testLabels\"\n",
        "COLLOCATION_POINTS      = \"collocationPoints\"\n",
        "INITIAL_POINTS          = \"initialPoints\"\n",
        "INITIAL_LABELS          = \"initialLabels\"\n",
        "BOUNDARY_POINTS_1       = \"boundaryPoints_1\"\n",
        "BOUNDARY_LABELS_1       = \"boundaryLabels_1\"\n",
        "BOUNDARY_POINTS_2       = \"boundaryPoints_2\"\n",
        "BOUNDARY_LABELS_2       = \"boundaryLabels_2\"\n",
        "BOUNDARY_POINTS_3       = \"boundaryPoints_3\"\n",
        "BOUNDARY_LABELS_3       = \"boundaryLabels_3\"\n",
        "TRAINING_LOSS_WEIGHT    = \"trainingLossWeight\"\n",
        "COLLOCATION_LOSS_WEIGHT = \"collocationLossWeight\"\n",
        "INITIAL_LOSS_WEIGHT     = \"initialLossWeight\"\n",
        "BOUNDARY_LOSS_WEIGHT    = \"boundaryLossWeight\""
      ],
      "metadata": {
        "id": "qzTpHcIC-MBC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **PDE Specific Functions**"
      ],
      "metadata": {
        "id": "dtd8yFCd9SFW"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def analyticalSolution():\n",
        "    pass"
      ],
      "metadata": {
        "id": "NCLZLIt9ecQp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def residual(T, x, t, dT_dt, dT_dx_2):\n",
        "    zeta = x - v*t \n",
        "    q_f = ((6*np.sqrt(3)*Q*m / np.pi*np.sqrt(np.pi)*a_f*b*c) * tf.math.exp(-(3*zeta**2)/(a_f**2)))\n",
        "    q_r = ((6*np.sqrt(3)*Q*n / np.pi*np.sqrt(np.pi)*a_r*b*c) * tf.math.exp(-(3*zeta**2)/(a_r**2)))\n",
        "    q = q_f + q_r\n",
        "    return (dT_dx_2 + (q/k) - alpha*dT_dt)\n",
        "\n",
        "def residual(phi, zeta, dphi_dzeta_2):\n",
        "    \"\"\"\n",
        "    PDE involving zeta, t, phi\n",
        "    \"\"\"\n",
        "    q_f = ((6*np.sqrt(3)*Q*m / np.pi*np.sqrt(np.pi)*a_f*b*c) * tf.math.exp(-(3*zeta**2)/(a_f**2)))\n",
        "    q_r = ((6*np.sqrt(3)*Q*n / np.pi*np.sqrt(np.pi)*a_r*b*c) * tf.math.exp(-(3*zeta**2)/(a_r**2)))\n",
        "    q = q_f + q_r\n",
        "\n",
        "    return (dphi_dzeta_2 + (q/k)*tf.math.exp((v*alpha*zeta)/2) - (((alpha**2)*(v**2))/4)*phi)\n",
        "\n",
        "def residual(phi, zeta, y, z, dphi_dzeta_2, dphi_dy_2, dphi_dz_2):\n",
        "    \"\"\"\n",
        "    PDE involving zeta, y, z, t, phi\n",
        "    \"\"\"\n",
        "    q_f = ((6*np.sqrt(3)*Q*m / np.pi*np.sqrt(np.pi)*a_f*b*c) * tf.math.exp(-(3*zeta**2)/(a_f**2) -(3*y**2)/(b**2) -(3*z**2)/(c**2)))\n",
        "    q_r = ((6*np.sqrt(3)*Q*n / np.pi*np.sqrt(np.pi)*a_r*b*c) * tf.math.exp(-(3*zeta**2)/(a_r**2) -(3*y**2)/(b**2) -(3*z**2)/(c**2)))\n",
        "    q = q_f + q_r\n",
        "    return (dphi_dzeta_2 + dphi_dy_2 + dphi_dz_2 + (q/k)*tf.math.exp((v*alpha*zeta)/2) - (((alpha**2)*(v**2))/4)*phi)\n",
        "\n",
        "def residual(phi, zeta, dT_dzeta_1, dT_dzeta_2, dT_dt_1):\n",
        "    \"\"\"\n",
        "    PDE involving zeta, t, T\n",
        "    \"\"\"\n",
        "    q_f = ((6*np.sqrt(3)*Q*m / np.pi*np.sqrt(np.pi)*a_f*b*c) * tf.math.exp(-(3*zeta**2)/(a_f**2)))\n",
        "    q_r = ((6*np.sqrt(3)*Q*n / np.pi*np.sqrt(np.pi)*a_r*b*c) * tf.math.exp(-(3*zeta**2)/(a_r**2)))\n",
        "    q = q_f + q_r\n",
        "    return (dT_dzeta_2 + (q/k) + alpha*v*dT_dzeta_1, - alpha*dT_dt_1)"
      ],
      "metadata": {
        "id": "k03_spmvedKV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def evaluateResidual(model, X_r):\n",
        "    \"\"\"\n",
        "    Evaluates residual involving zeta, y, t, phi\n",
        "    \"\"\"\n",
        "\n",
        "    with tf.GradientTape(persistent=True) as tape:\n",
        "        x, y, z, t, zeta = X_r[:, 0:1], X_r[:, 1:2], X_r[:, 2:3], X_r[:, 3:4], X_r[:, 4:5]\n",
        "        \n",
        "        tape.watch(x)\n",
        "        tape.watch(y)\n",
        "        tape.watch(z)\n",
        "        tape.watch(t)\n",
        "        tape.watch(zeta)\n",
        "        \n",
        "        phi = model(tf.stack([x[:, 0], y[:, 0], z[:, 0], t[:, 0], zeta[:, 0]], axis=1))\n",
        "        \n",
        "        dphi_dzeta_1 = tape.gradient(phi, zeta)\n",
        "        dphi_dy_1 = tape.gradient(phi, y)\n",
        "        dphi_dz_1 = tape.gradient(phi, z)\n",
        "        \n",
        "    dphi_dzeta_2 = tape.gradient(dphi_dzeta_1, zeta)\n",
        "    dphi_dy_2 = tape.gradient(dphi_dy_1, y)\n",
        "    dphi_dz_2 = tape.gradient(dphi_dz_1, z)\n",
        "\n",
        "    del tape\n",
        "    \n",
        "    return residual(phi, zeta, y, z, dphi_dzeta_2, dphi_dy_2, dphi_dz_2)\n",
        "\n",
        "def evaluateResidual(model, X_r):\n",
        "    \"\"\"\n",
        "    Evaluates residual involving zeta, phi\n",
        "    \"\"\"\n",
        "\n",
        "    with tf.GradientTape(persistent=True) as tape:\n",
        "        x, t, zeta = X_r[:, 0:1], X_r[:, 1:2], X_r[:, 2:3]\n",
        "        \n",
        "        tape.watch(x)\n",
        "        tape.watch(t)\n",
        "        tape.watch(zeta)\n",
        "        \n",
        "        T = model(tf.stack([x[:, 0], t[:, 0], zeta[:, 0]], axis=1))\n",
        "        \n",
        "        dT_dzeta_1 = tape.gradient(T, zeta)\n",
        "        dT_dt_1 = tape.gradient(T, t)\n",
        "        \n",
        "    dT_dzeta_2 = tape.gradient(dT_dzeta_1, zeta)   \n",
        "\n",
        "    del tape\n",
        "    \n",
        "    return residual(T, zeta, dT_dzeta_1, dT_dzeta_2, dT_dt_1)"
      ],
      "metadata": {
        "id": "GpZw2C-MgEL7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def evaluateBoundaryEqn_1(model, X_b):\n",
        "    \"\"\"\n",
        "    Evaluates residual involving zeta, y, t, phi\n",
        "    \"\"\"\n",
        "    \n",
        "    with tf.GradientTape(persistent=True) as tape:\n",
        "        x, y, z, t, zeta = X_b[:, 0:1], X_b[:, 1:2], X_b[:, 2:3], X_b[:, 3:4], X_b[:, 4:5]\n",
        "\n",
        "        tape.watch(x)\n",
        "        tape.watch(y)\n",
        "        tape.watch(z)\n",
        "        tape.watch(t)\n",
        "        tape.watch(zeta)\n",
        "\n",
        "        phi = model(tf.stack([x[:, 0], y[:, 0], z[:, 0], t[:, 0], zeta[:, 0]], axis=1))\n",
        "\n",
        "    dphi_dx_1 = tape.gradient(phi, x)\n",
        "\n",
        "    del tape\n",
        "\n",
        "    return dphi_dx_1 - (v*alpha*phi)/2 + (h*phi)/k"
      ],
      "metadata": {
        "id": "n7PDOAZPg0cF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def evaluateBoundaryEqn_2(model, X_b):\n",
        "    \"\"\"\n",
        "    Evaluates residual involving zeta, y, t, phi\n",
        "    \"\"\"\n",
        "\n",
        "    with tf.GradientTape(persistent=True) as tape:\n",
        "        x, y, z, t, zeta = X_b[:, 0:1], X_b[:, 1:2], X_b[:, 2:3], X_b[:, 3:4], X_b[:, 4:5]\n",
        "\n",
        "        tape.watch(x)\n",
        "        tape.watch(y)\n",
        "        tape.watch(z)\n",
        "        tape.watch(t)\n",
        "        tape.watch(zeta)\n",
        "\n",
        "        phi = model(tf.stack([x[:, 0], y[:, 0], z[:, 0], t[:, 0], zeta[:, 0]], axis=1))\n",
        "\n",
        "    dphi_dx_1 = tape.gradient(phi, x)\n",
        "\n",
        "    del tape\n",
        "\n",
        "    return (-dphi_dx_1) + (v*alpha*phi)/2 + (h*phi)/k"
      ],
      "metadata": {
        "id": "BKJ-Hbx_fo6L"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def evaluateBoundaryEqn_3(model, X_b):\n",
        "    \"\"\"\n",
        "    Evaluates residual involving zeta, y, t, phi\n",
        "    \"\"\"\n",
        "\n",
        "    with tf.GradientTape(persistent=True) as tape:\n",
        "        x, y, z, t, zeta = X_b[:, 0:1], X_b[:, 1:2], X_b[:, 2:3], X_b[:, 3:4], X_b[:, 4:5]\n",
        "\n",
        "        tape.watch(x)\n",
        "        tape.watch(y)\n",
        "        tape.watch(z)\n",
        "        tape.watch(t)\n",
        "        tape.watch(zeta)\n",
        "\n",
        "        phi = model(tf.stack([x[:, 0], y[:, 0], z[:, 0], t[:, 0], zeta[:, 0]], axis=1))\n",
        "\n",
        "    dphi_dz_1 = tape.gradient(phi, z)\n",
        "\n",
        "    del tape\n",
        "\n",
        "    return dphi_dz_1"
      ],
      "metadata": {
        "id": "HsW8fRM1b5lO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **PINN**\n"
      ],
      "metadata": {
        "id": "S-OAFH2Q9WNi"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class PINN:\n",
        "\n",
        "    def __init__ (self, inputParams):\n",
        "        \n",
        "        self.inputLayerDim = inputParams[INPUT_LAYER_DIM]\n",
        "        self.outputLayerDim = inputParams[OUTPUT_LAYER_DIM]\n",
        "        self.hiddenLayersDim = inputParams[HIDDEN_LAYERS_DIM]\n",
        "        self.lr = inputParams[LEARNING_RATE]\n",
        "        self.optim = tf.keras.optimizers.Adam(learning_rate=self.lr)\n",
        "        self.epochs = inputParams[EPOCHS]\n",
        "        self.print_interval = inputParams[PRINT_INTERVAL]\n",
        "        self.X_train = inputParams[TRAINING_POINTS]\n",
        "        self.y_train = inputParams[TRAINING_LABELS]\n",
        "        self.X_test = inputParams[TEST_POINTS]\n",
        "        self.y_test = inputParams[TEST_LABELS]\n",
        "        self.X_collocation = inputParams[COLLOCATION_POINTS]\n",
        "        self.evaluateResidual = inputParams[EVALUATE_RESIDUAL]\n",
        "        self.X_initial = inputParams[INITIAL_POINTS]\n",
        "        self.y_initial = inputParams[INITIAL_LABELS]\n",
        "        self.X_boundary_1 = inputParams[BOUNDARY_POINTS_1]\n",
        "        self.y_boundary_1 = inputParams[BOUNDARY_LABELS_1]\n",
        "        self.X_boundary_2 = inputParams[BOUNDARY_POINTS_2]\n",
        "        self.y_boundary_2 = inputParams[BOUNDARY_LABELS_2]\n",
        "        self.X_boundary_3 = inputParams[BOUNDARY_POINTS_3]\n",
        "        self.y_boundary_3 = inputParams[BOUNDARY_LABELS_3]\n",
        "        self.evaluateBoundaryEqn_1 = inputParams[EVALUATE_BOUNDARY_EQN_1]\n",
        "        self.evaluateBoundaryEqn_2 = inputParams[EVALUATE_BOUNDARY_EQN_2]\n",
        "        self.evaluateBoundaryEqn_3 = inputParams[EVALUATE_BOUNDARY_EQN_3]\n",
        "\n",
        "        self.weight_train = inputParams[TRAINING_LOSS_WEIGHT]\n",
        "        self.weight_collocation = inputParams[COLLOCATION_LOSS_WEIGHT]\n",
        "        self.weight_initial = inputParams[INITIAL_LOSS_WEIGHT]\n",
        "        self.weight_boundary = inputParams[BOUNDARY_LOSS_WEIGHT]\n",
        "\n",
        "        self.X_batch = None\n",
        "        self.y_batch = None\n",
        "        self.batchDescription = None\n",
        "        \n",
        "        self.initModel()\n",
        "        self.modelSummary()\n",
        "\n",
        "        # self.extendModel()\n",
        "\n",
        "    def initModel(self):\n",
        "\n",
        "        initializer = tf.keras.initializers.GlorotUniform(seed=SEED)\n",
        "\n",
        "        self.model = tf.keras.Sequential()\n",
        "        self.model.add(tf.keras.layers.Dense(\n",
        "            self.hiddenLayersDim[0], \n",
        "            input_dim=self.inputLayerDim, \n",
        "            # activation=tf.keras.activations.get('tanh'),\n",
        "            # activation=tf.keras.activations.get('relu'),\n",
        "            activation=tf.keras.activations.get('elu'),\n",
        "            name=\"hidden_0\",\n",
        "            kernel_initializer=initializer\n",
        "        ))    \n",
        "        for i in range(1, len(self.hiddenLayersDim)):\n",
        "            self.model.add(tf.keras.layers.Dense(\n",
        "                self.hiddenLayersDim[i], \n",
        "                # activation=tf.keras.activations.get('tanh'),\n",
        "                # activation=tf.keras.activations.get('relu'),\n",
        "                activation=tf.keras.activations.get('elu'),\n",
        "                name=\"hidden_\" + str(i+1),\n",
        "                kernel_initializer=initializer\n",
        "            ))\n",
        "        self.model.add(tf.keras.layers.Dense(\n",
        "            self.outputLayerDim,\n",
        "            name=\"output\",\n",
        "            kernel_initializer=initializer\n",
        "        ))\n",
        "\n",
        "    # def extendModel(self):\n",
        "\n",
        "    #     self.extendedModel = tf.keras.Sequential()\n",
        "    #     self.extendedModel.add(tf.keras.layers.Dense(\n",
        "    #         2, \n",
        "    #         input_dim=1, \n",
        "    #         activation=tf.keras.activations.get('relu')\n",
        "    #     ))\n",
        "    #     self.extendedModel.add(tf.keras.layers.Dense(\n",
        "    #         2, \n",
        "    #         activation=tf.keras.activations.get('relu')\n",
        "    #     ))    \n",
        "    #     self.extendedModel.add(tf.keras.layers.Dense(\n",
        "    #         1\n",
        "    #     ))\n",
        "\n",
        "    #     print(self.extendedModel.summary())\n",
        "\n",
        "    #     self.extendedModel.compile(\n",
        "    #         optimizer='adam',\n",
        "    #         loss=tf.keras.metrics.mean_squared_error,\n",
        "    #         metrics=['accuracy']\n",
        "    #     )\n",
        "\n",
        "    def modelSummary(self):\n",
        "        print(self.model.summary())\n",
        "\n",
        "    def computeLoss(self):\n",
        "\n",
        "        loss = 0\n",
        "\n",
        "        if (self.X_train is not None):\n",
        "            loss_train = tf.reduce_mean(tf.square(self.y_train - self.model(self.X_train)))\n",
        "            if (self.epochNo % self.print_interval) == 0:\n",
        "                print('It {:05d}: Train loss = {:10.8e}'.format(self.epochNo, loss_train))\n",
        "            loss += (self.weight_train) * loss_train\n",
        "\n",
        "        if (self.X_collocation is not None):\n",
        "            r = self.evaluateResidual(self.model, self.X_collocation)\n",
        "            loss_collocation = tf.reduce_mean(tf.square(r))\n",
        "            if (self.epochNo % self.print_interval) == 0:\n",
        "                print('It {:05d}: Collocation loss = {:10.8e}'.format(self.epochNo, loss_collocation))\n",
        "            loss += (self.weight_collocation) * loss_collocation\n",
        "        \n",
        "        if (self.X_initial is not None):\n",
        "            loss_initial = tf.reduce_mean(tf.square(self.y_initial - self.model(self.X_initial)))\n",
        "            if (self.epochNo % self.print_interval) == 0:\n",
        "                print('It {:05d}: Initial loss = {:10.8e}'.format(self.epochNo, loss_initial))\n",
        "            loss += (self.weight_initial) * loss_initial\n",
        "\n",
        "        if (self.X_boundary_1 is not None):\n",
        "            b_1 = self.evaluateBoundaryEqn_1(self.model, self.X_boundary_1)\n",
        "            loss_boundary = tf.reduce_mean(tf.square(b_1))\n",
        "            if (self.epochNo % self.print_interval) == 0:\n",
        "                print('It {:05d}: Boundary Start loss = {:10.8e}'.format(self.epochNo, loss_boundary))\n",
        "            loss += (self.weight_boundary) * loss_boundary\n",
        "\n",
        "        if (self.X_boundary_2 is not None):\n",
        "            b_2 = self.evaluateBoundaryEqn_2(self.model, self.X_boundary_2)\n",
        "            loss_boundary = tf.reduce_mean(tf.square(b_2))\n",
        "            if (self.epochNo % self.print_interval) == 0:\n",
        "                print('It {:05d}: Boundary End loss = {:10.8e}'.format(self.epochNo, loss_boundary))\n",
        "            loss += (self.weight_boundary) * loss_boundary\n",
        "\n",
        "        if (self.X_boundary_3 is not None):\n",
        "            b_3 = self.evaluateBoundaryEqn_3(self.model, self.X_boundary_3)\n",
        "            loss_boundary = tf.reduce_mean(tf.square(b_3))\n",
        "            if (self.epochNo % self.print_interval) == 0:\n",
        "                print('It {:05d}: Boundary Bottom loss = {:10.8e}'.format(self.epochNo, loss_boundary))\n",
        "            loss += (self.weight_boundary) * loss_boundary\n",
        "\n",
        "        return loss\n",
        "\n",
        "    def getLossAndGradientOfParams(self):\n",
        "    \n",
        "        with tf.GradientTape(persistent=True) as tape:\n",
        "            tape.watch(self.model.trainable_variables)\n",
        "            loss = self.computeLoss()\n",
        "\n",
        "        g = tape.gradient(loss, self.model.trainable_variables)\n",
        "        del tape\n",
        "\n",
        "        return loss, g\n",
        "\n",
        "    # Define one training step as a TensorFlow function to increase speed of training\n",
        "    # @tf.function\n",
        "    def train_step(self):\n",
        "        \n",
        "        # Compute current loss and gradient w.r.t. parameters\n",
        "        loss, grad_theta = self.getLossAndGradientOfParams()\n",
        "\n",
        "        if (DEBUG):\n",
        "            print('-----train_step-----')\n",
        "            print(f'loss : {loss}')\n",
        "            print(f'grad_theta : {grad_theta}')\n",
        "        \n",
        "        # Perform gradient descent step\n",
        "        self.optim.apply_gradients(zip(grad_theta, self.model.trainable_variables))\n",
        "        \n",
        "        return loss\n",
        "\n",
        "    def train(self):\n",
        "\n",
        "        N = self.epochs\n",
        "\n",
        "        # Start timer\n",
        "        startTime = time()\n",
        "\n",
        "        for epochNo in range(self.epochs):\n",
        "\n",
        "            self.epochNo = epochNo\n",
        "\n",
        "            loss = 0\n",
        "            \n",
        "            # if (self.X_train is not None):\n",
        "            #     self.X_batch = self.X_train\n",
        "            #     self.y_batch = self.y_train\n",
        "            #     # for (X_batch, y_batch) in zip(self.X_train.batch(BATCH_SIZE), self.y_train.batch(BATCH_SIZE)):\n",
        "            #     #     self.X_batch = X_batch\n",
        "            #     #     self.y_batch = y_batch\n",
        "            #     self.batchDescription = TRAINING_POINTS\n",
        "            #     loss += self.train_step()\n",
        "\n",
        "            # if (self.X_collocation is not None):\n",
        "            #     self.X_batch = self.X_collocation\n",
        "            #     # for X_batch in self.X_collocation.batch(BATCH_SIZE):\n",
        "            #     #     self.X_batch = X_batch\n",
        "            #     #     # self.y_batch = y_batch (No need y_batch)\n",
        "            #     self.batchDescription = COLLOCATION_POINTS\n",
        "            #     loss += self.train_step()\n",
        "\n",
        "            # if (self.X_initial is not None):\n",
        "            #     self.X_batch = self.X_initial\n",
        "            #     self.y_batch = self.y_initial\n",
        "            #     # for (X_batch, y_batch) in zip(self.X_initial.batch(BATCH_SIZE), self.y_initial.batch(BATCH_SIZE)):\n",
        "            #     #     self.X_batch = X_batch\n",
        "            #     #     self.y_batch = y_batch\n",
        "            #     self.batchDescription = INITIAL_POINTS\n",
        "            #     loss += self.train_step()\n",
        "\n",
        "            loss += self.train_step()\n",
        "            \n",
        "            # Output current loss after specified interval of epochs\n",
        "            if (epochNo % self.print_interval) == 0:\n",
        "                print('It {:05d}: loss = {:10.8e}\\n'.format(epochNo, loss))         \n",
        "\n",
        "        # Print computation time\n",
        "        print('\\nComputation time: {} seconds'.format(time()-startTime))"
      ],
      "metadata": {
        "id": "X6qQr7dfdyfL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def plotLearnedFunction(X, upreds):\n",
        "    fig, axs = plt.subplots(len(upreds), figsize=(6, 2*len(upreds)))\n",
        "    fig.suptitle('Learned NN Function')\n",
        "    for i in range(len(upreds)):\n",
        "        axs[i].plot(X, upreds[i], label='model_' + str(50*i), c='red')\n",
        "        axs[i].plot(X, analyticalSolution(X.numpy(), 0.5, 1), label='actual', ls='--', c='black')\n",
        "        axs[i].legend(loc='center left', bbox_to_anchor=(1, 0.5))\n",
        "    for ax in axs:\n",
        "        ax.label_outer()\n",
        "    plt.show()"
      ],
      "metadata": {
        "id": "Rr7oriTmBldl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **Training and Test Data**"
      ],
      "metadata": {
        "id": "h9sIL0HAG4aH"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "DTYPE = 'float64'\n",
        "tf.keras.backend.set_floatx(DTYPE)"
      ],
      "metadata": {
        "id": "A-BtW0WGGBve"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "coordinates_data = pd.read_excel('/content/PINN_X_coordinates.xlsx')\n",
        "# coordinates = coordinates_data.iloc[:, :1].values\n",
        "coordinates = coordinates_data.iloc[:, :3].values"
      ],
      "metadata": {
        "id": "bs4M4k9EG8yT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "NUM_PARTICLES = coordinates.shape[0]"
      ],
      "metadata": {
        "id": "wA0Vrwbub5eU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "temperature_time_data = pd.read_excel('/content/pinn_x_Tt.xlsx')\n",
        "times = temperature_time_data.iloc[:, :1].values\n",
        "temperatures = temperature_time_data.iloc[:, range(1, NUM_PARTICLES*2, 2)].values"
      ],
      "metadata": {
        "id": "g6SFv_WKJF5R"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "TIME_STEPS = times.shape[0]"
      ],
      "metadata": {
        "id": "O3o8bbUtcMQB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "DEPOSITION_TIME_STEP = 63"
      ],
      "metadata": {
        "id": "Kp1puOAIhPaC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### **$T_{actual}(t)$ Visulatization**"
      ],
      "metadata": {
        "id": "oK-vHc90hA6O"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "fig = plt.figure(figsize=(15,15))\n",
        "ax = fig.add_subplot(111, projection='3d')\n",
        "\n",
        "for i in range(0, 63):\n",
        "    ax.plot(coordinates[:, 0], \n",
        "            times[i][0]*np.ones(NUM_PARTICLES),\n",
        "            temperatures[i, :])\n",
        "\n",
        "ax.view_init(30, 60)\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "QhDtXl0nryoq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### **x - t - zeta - phi**"
      ],
      "metadata": {
        "id": "EepRfsP5gzgW"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "X = None\n",
        "\n",
        "# fig = plt.figure(figsize=(15,15))\n",
        "# ax = fig.add_subplot(111, projection='3d')\n",
        "\n",
        "for i in range(0, NUM_PARTICLES):\n",
        "\n",
        "    tt = times[:DEPOSITION_TIME_STEP, :]\n",
        "    xx = np.array([coordinates[i:i+1, :1][0]]*tt.shape[0])\n",
        "    yy = np.array([coordinates[i:i+1, 1:2][0]]*tt.shape[0])\n",
        "    zz = np.array([coordinates[i:i+1, 2:3][0]]*tt.shape[0])\n",
        "    zetazeta = (xx - (v*tt - 0.06))\n",
        "    TT = temperatures[:DEPOSITION_TIME_STEP, i:i+1]\n",
        "    pp = (TT - T_0) / np.exp(-(v*alpha*zz)/2)\n",
        "    ff = np.hstack((xx, yy, zz, tt, zetazeta, pp, TT))\n",
        "\n",
        "    if (i == 0):\n",
        "        X_boundary_1 = ff\n",
        "    elif (i == NUM_PARTICLES-1):\n",
        "        X_boundary_2 = ff\n",
        "\n",
        "    # ax.plot(tt, xx, TT)\n",
        "\n",
        "    # ff = []\n",
        "    # x_curr = coordinates[i, 0]\n",
        "    # for j in range(DEPOSITION_TIME_STEP):\n",
        "    #     t_curr = times[j, 0]\n",
        "    #     z_curr = x_curr - (v*t_curr - 0.06)\n",
        "    #     if (z_curr <= 0):\n",
        "    #         T_curr =  temperatures[j, i]\n",
        "    #         p_curr =  (T_curr - T_0) / np.exp(-(v*alpha*z_curr)/2)\n",
        "    #     ff.append([x_curr, t_curr, z_curr, p_curr])\n",
        "\n",
        "    # ff = np.array(ff)\n",
        "\n",
        "    if X is None:\n",
        "        X = ff\n",
        "    else:\n",
        "        X = np.vstack((X, ff))\n",
        "\n",
        "# ax.view_init(30, -90)\n",
        "# plt.show()\n",
        "\n",
        "y = X[:, -2:-1]\n",
        "# y = X[:, -1:]\n",
        "X = X[:, :-2]"
      ],
      "metadata": {
        "id": "jfY8UuQ7bzdX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# X_extended = tf.Variable(X)\n",
        "# y_extended = tf.Variable(X[:, -1:])"
      ],
      "metadata": {
        "id": "S21evMhxH7jX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### **Train Test Split**"
      ],
      "metadata": {
        "id": "m2nx8EQghJKW"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=SEED)"
      ],
      "metadata": {
        "id": "1vbRwMMrcavU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.preprocessing import StandardScaler\n",
        "sc = StandardScaler()\n",
        "X_train = sc.fit_transform(X_train)\n",
        "X_test = sc.transform(X_test)"
      ],
      "metadata": {
        "id": "aqJQbg1Ncme8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# X_train = tf.data.Dataset.from_tensor_slices(tf.Variable(X_train))\n",
        "# y_train = tf.data.Dataset.from_tensor_slices(tf.Variable(y_train))\n",
        "# X_test = tf.data.Dataset.from_tensor_slices(tf.Variable(X_test))\n",
        "# y_test = tf.data.Dataset.from_tensor_slices(tf.Variable(y_test))\n",
        "\n",
        "X_train = tf.Variable(X_train)\n",
        "y_train = tf.Variable(y_train)\n",
        "X_test = tf.Variable(X_train)\n",
        "y_test = tf.Variable(y_test)"
      ],
      "metadata": {
        "id": "2d_ufFq7dZkJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **Collocation Points**"
      ],
      "metadata": {
        "id": "FemjkRMdDGs9"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "X_collocation = X"
      ],
      "metadata": {
        "id": "_MBONvAP4Ong"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# X_collocation = tf.data.Dataset.from_tensor_slices(tf.Variable(X_collocation, dtype=DTYPE))\n",
        "X_collocation = tf.Variable(X_collocation)"
      ],
      "metadata": {
        "id": "JOBaflU44V1h"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **Initial Condition Points**"
      ],
      "metadata": {
        "id": "jNoudHlXC3i2"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "X_initial = np.hstack((coordinates, np.zeros((coordinates.shape[0], 1)), coordinates[:, :1]+0.06))\n",
        "y_initial = np.zeros(coordinates.shape)\n",
        "# y_initial = np.ones(coordinates.shape)*T_0"
      ],
      "metadata": {
        "id": "QEyLUkvO2Pz7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# X_initial = tf.data.Dataset.from_tensor_slices(tf.Variable(X_initial, dtype=DTYPE))\n",
        "# y_initial = tf.data.Dataset.from_tensor_slices(tf.Variable(y_initial, dtype=DTYPE))\n",
        "X_initial = tf.Variable(X_initial)\n",
        "y_initial = tf.Variable(y_initial)"
      ],
      "metadata": {
        "id": "zddmKfip4eLe"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **Boundary Condition Points**"
      ],
      "metadata": {
        "id": "i5yD17drbW46"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "X_boundary_1 = tf.Variable(X_boundary_1)\n",
        "X_boundary_2 = tf.Variable(X_boundary_2)\n",
        "X_boundary_3 = tf.Variable(X)"
      ],
      "metadata": {
        "id": "GL5nqcGkKP4U"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **Model**"
      ],
      "metadata": {
        "id": "HqDfV__IF4mp"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "inputParams = {\n",
        "    INPUT_LAYER_DIM         : 5,\n",
        "    OUTPUT_LAYER_DIM        : 1,\n",
        "    HIDDEN_LAYERS_DIM       : [4, 8, 16, 8, 4],\n",
        "    ANALYTICAL_SOLUTION     : analyticalSolution,\n",
        "    RESIDUAL                : residual,\n",
        "    EVALUATE_RESIDUAL       : evaluateResidual,\n",
        "    EVALUATE_BOUNDARY_EQN_1 : evaluateBoundaryEqn_1,\n",
        "    EVALUATE_BOUNDARY_EQN_2 : evaluateBoundaryEqn_2,\n",
        "    EVALUATE_BOUNDARY_EQN_3 : evaluateBoundaryEqn_3,\n",
        "    LEARNING_RATE           : 1e-2,\n",
        "    EPOCHS                  : 1001,\n",
        "    PRINT_INTERVAL          : 25,\n",
        "    TRAINING_POINTS         : X_train,\n",
        "    TRAINING_LABELS         : y_train,\n",
        "    TEST_POINTS             : None,\n",
        "    TEST_LABELS             : None,\n",
        "    COLLOCATION_POINTS      : X_collocation,\n",
        "    INITIAL_POINTS          : X_initial,\n",
        "    INITIAL_LABELS          : y_initial,\n",
        "    BOUNDARY_POINTS_1       : X_boundary_1,\n",
        "    BOUNDARY_LABELS_1       : None,\n",
        "    BOUNDARY_POINTS_2       : X_boundary_2,\n",
        "    BOUNDARY_LABELS_2       : None,\n",
        "    BOUNDARY_POINTS_3       : X_boundary_3,\n",
        "    BOUNDARY_LABELS_3       : None,\n",
        "    TRAINING_LOSS_WEIGHT    : 1,\n",
        "    COLLOCATION_LOSS_WEIGHT : 1,\n",
        "    INITIAL_LOSS_WEIGHT     : 1,\n",
        "    BOUNDARY_LOSS_WEIGHT    : 1,\n",
        "}"
      ],
      "metadata": {
        "id": "DdHcyN5T9jLm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "tf.keras.backend.clear_session()"
      ],
      "metadata": {
        "id": "YQxIa5bqDq9l"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model = PINN(inputParams)"
      ],
      "metadata": {
        "id": "d_cJTbwAC7gb",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "80986a8e-43c1-4c4f-a7bc-2c1a51043918"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " hidden_0 (Dense)            (None, 4)                 24        \n",
            "                                                                 \n",
            " hidden_2 (Dense)            (None, 8)                 40        \n",
            "                                                                 \n",
            " hidden_3 (Dense)            (None, 16)                144       \n",
            "                                                                 \n",
            " hidden_4 (Dense)            (None, 8)                 136       \n",
            "                                                                 \n",
            " hidden_5 (Dense)            (None, 4)                 36        \n",
            "                                                                 \n",
            " output (Dense)              (None, 1)                 5         \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 385\n",
            "Trainable params: 385\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "None\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "upreds, losses = model.train()"
      ],
      "metadata": {
        "id": "dAzbDglKC8u1",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f486df96-8589-4268-dfb2-7507c0d0efe6"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "It 00000: Train loss = 1.86419879e+12\n",
            "It 00000: Collocation loss = 6.12740194e+09\n",
            "It 00000: Initial loss = 6.72721412e-04\n",
            "It 00000: Boundary Start loss = 3.66143383e+04\n",
            "It 00000: Boundary End loss = 3.96430133e+04\n",
            "It 00000: Boundary Bottom loss = 4.97256440e-02\n",
            "It 00000: loss = 1.87032627e+12\n",
            "\n",
            "It 00025: Train loss = 1.86419791e+12\n",
            "It 00025: Collocation loss = 3.04872117e+07\n",
            "It 00025: Initial loss = 2.75576609e-04\n",
            "It 00025: Boundary Start loss = 1.67639345e+02\n",
            "It 00025: Boundary End loss = 2.12198968e+02\n",
            "It 00025: Boundary Bottom loss = 1.81275334e-04\n",
            "It 00025: loss = 1.86422840e+12\n",
            "\n",
            "It 00050: Train loss = 1.86419786e+12\n",
            "It 00050: Collocation loss = 2.09513434e+06\n",
            "It 00050: Initial loss = 1.89244393e-04\n",
            "It 00050: Boundary Start loss = 1.05233019e+01\n",
            "It 00050: Boundary End loss = 1.58517949e+01\n",
            "It 00050: Boundary Bottom loss = 1.52822686e-04\n",
            "It 00050: loss = 1.86419995e+12\n",
            "\n",
            "It 00075: Train loss = 1.86419784e+12\n",
            "It 00075: Collocation loss = 5.74560129e+05\n",
            "It 00075: Initial loss = 1.71319018e-04\n",
            "It 00075: Boundary Start loss = 5.16130943e+00\n",
            "It 00075: Boundary End loss = 2.46191602e+00\n",
            "It 00075: Boundary Bottom loss = 1.05802984e-04\n",
            "It 00075: loss = 1.86419841e+12\n",
            "\n",
            "It 00100: Train loss = 1.86419785e+12\n",
            "It 00100: Collocation loss = 1.01224879e+05\n",
            "It 00100: Initial loss = 4.50364926e-05\n",
            "It 00100: Boundary Start loss = 8.30790400e-01\n",
            "It 00100: Boundary End loss = 7.94843188e-01\n",
            "It 00100: Boundary Bottom loss = 1.24637137e-04\n",
            "It 00100: loss = 1.86419795e+12\n",
            "\n",
            "It 00125: Train loss = 1.86419784e+12\n",
            "It 00125: Collocation loss = 5.08009338e+04\n",
            "It 00125: Initial loss = 1.51131700e-05\n",
            "It 00125: Boundary Start loss = 5.07485284e-01\n",
            "It 00125: Boundary End loss = 4.53591956e-01\n",
            "It 00125: Boundary Bottom loss = 1.42338642e-04\n",
            "It 00125: loss = 1.86419790e+12\n",
            "\n",
            "It 00150: Train loss = 1.86419784e+12\n",
            "It 00150: Collocation loss = 3.79923133e+04\n",
            "It 00150: Initial loss = 6.57087696e-06\n",
            "It 00150: Boundary Start loss = 4.58583104e-01\n",
            "It 00150: Boundary End loss = 3.10966260e-01\n",
            "It 00150: Boundary Bottom loss = 1.50753017e-04\n",
            "It 00150: loss = 1.86419788e+12\n",
            "\n",
            "It 00175: Train loss = 1.86419784e+12\n",
            "It 00175: Collocation loss = 3.43449661e+04\n",
            "It 00175: Initial loss = 4.05525350e-06\n",
            "It 00175: Boundary Start loss = 3.87812596e-01\n",
            "It 00175: Boundary End loss = 3.04983302e-01\n",
            "It 00175: Boundary Bottom loss = 1.54024507e-04\n",
            "It 00175: loss = 1.86419788e+12\n",
            "\n",
            "It 00200: Train loss = 1.86419784e+12\n",
            "It 00200: Collocation loss = 3.24552126e+04\n",
            "It 00200: Initial loss = 3.26719005e-06\n",
            "It 00200: Boundary Start loss = 3.47278244e-01\n",
            "It 00200: Boundary End loss = 2.93746793e-01\n",
            "It 00200: Boundary Bottom loss = 1.53118932e-04\n",
            "It 00200: loss = 1.86419788e+12\n",
            "\n",
            "It 00225: Train loss = 1.86419784e+12\n",
            "It 00225: Collocation loss = 3.08891244e+04\n",
            "It 00225: Initial loss = 2.91737619e-06\n",
            "It 00225: Boundary Start loss = 3.18661418e-01\n",
            "It 00225: Boundary End loss = 2.76761890e-01\n",
            "It 00225: Boundary Bottom loss = 1.50133553e-04\n",
            "It 00225: loss = 1.86419788e+12\n",
            "\n",
            "It 00250: Train loss = 1.86419784e+12\n",
            "It 00250: Collocation loss = 2.94157377e+04\n",
            "It 00250: Initial loss = 2.70142736e-06\n",
            "It 00250: Boundary Start loss = 2.94401739e-01\n",
            "It 00250: Boundary End loss = 2.58503479e-01\n",
            "It 00250: Boundary Bottom loss = 1.46501697e-04\n",
            "It 00250: loss = 1.86419787e+12\n",
            "\n",
            "It 00275: Train loss = 1.86419784e+12\n",
            "It 00275: Collocation loss = 2.80190545e+04\n",
            "It 00275: Initial loss = 2.52992501e-06\n",
            "It 00275: Boundary Start loss = 2.72340303e-01\n",
            "It 00275: Boundary End loss = 2.40838176e-01\n",
            "It 00275: Boundary Bottom loss = 1.42733882e-04\n",
            "It 00275: loss = 1.86419787e+12\n",
            "\n",
            "It 00300: Train loss = 1.86419784e+12\n",
            "It 00300: Collocation loss = 2.67025269e+04\n",
            "It 00300: Initial loss = 2.37744823e-06\n",
            "It 00300: Boundary Start loss = 2.51974863e-01\n",
            "It 00300: Boundary End loss = 2.24306631e-01\n",
            "It 00300: Boundary Bottom loss = 1.38996466e-04\n",
            "It 00300: loss = 1.86419787e+12\n",
            "\n",
            "It 00325: Train loss = 1.86419784e+12\n",
            "It 00325: Collocation loss = 2.54682801e+04\n",
            "It 00325: Initial loss = 2.23897862e-06\n",
            "It 00325: Boundary Start loss = 2.33213944e-01\n",
            "It 00325: Boundary End loss = 2.09029669e-01\n",
            "It 00325: Boundary Bottom loss = 1.35343127e-04\n",
            "It 00325: loss = 1.86419787e+12\n",
            "\n",
            "It 00350: Train loss = 1.86419784e+12\n",
            "It 00350: Collocation loss = 2.43167679e+04\n",
            "It 00350: Initial loss = 2.11399932e-06\n",
            "It 00350: Boundary Start loss = 2.16012502e-01\n",
            "It 00350: Boundary End loss = 1.95032045e-01\n",
            "It 00350: Boundary Bottom loss = 1.31788604e-04\n",
            "It 00350: loss = 1.86419787e+12\n",
            "\n",
            "It 00375: Train loss = 1.86419784e+12\n",
            "It 00375: Collocation loss = 2.32472016e+04\n",
            "It 00375: Initial loss = 2.00253445e-06\n",
            "It 00375: Boundary Start loss = 2.00336945e-01\n",
            "It 00375: Boundary End loss = 1.82288170e-01\n",
            "It 00375: Boundary Bottom loss = 1.28342330e-04\n",
            "It 00375: loss = 1.86419787e+12\n",
            "\n",
            "It 00400: Train loss = 1.86419784e+12\n",
            "It 00400: Collocation loss = 2.22577972e+04\n",
            "It 00400: Initial loss = 1.90431857e-06\n",
            "It 00400: Boundary Start loss = 1.86140760e-01\n",
            "It 00400: Boundary End loss = 1.70752762e-01\n",
            "It 00400: Boundary Bottom loss = 1.25012318e-04\n",
            "It 00400: loss = 1.86419787e+12\n",
            "\n",
            "It 00425: Train loss = 1.86419784e+12\n",
            "It 00425: Collocation loss = 2.13457998e+04\n",
            "It 00425: Initial loss = 1.81879679e-06\n",
            "It 00425: Boundary Start loss = 1.73357886e-01\n",
            "It 00425: Boundary End loss = 1.60372794e-01\n",
            "It 00425: Boundary Bottom loss = 1.21805318e-04\n",
            "It 00425: loss = 1.86419787e+12\n",
            "\n",
            "It 00450: Train loss = 1.86419784e+12\n",
            "It 00450: Collocation loss = 2.05077211e+04\n",
            "It 00450: Initial loss = 1.74530394e-06\n",
            "It 00450: Boundary Start loss = 1.61911197e-01\n",
            "It 00450: Boundary End loss = 1.51085066e-01\n",
            "It 00450: Boundary Bottom loss = 1.18725923e-04\n",
            "It 00450: loss = 1.86419786e+12\n",
            "\n",
            "It 00475: Train loss = 1.86419784e+12\n",
            "It 00475: Collocation loss = 1.97394910e+04\n",
            "It 00475: Initial loss = 1.68311326e-06\n",
            "It 00475: Boundary Start loss = 1.51715074e-01\n",
            "It 00475: Boundary End loss = 1.42818106e-01\n",
            "It 00475: Boundary Bottom loss = 1.15776843e-04\n",
            "It 00475: loss = 1.86419786e+12\n",
            "\n",
            "It 00500: Train loss = 1.86419784e+12\n",
            "It 00500: Collocation loss = 1.90366380e+04\n",
            "It 00500: Initial loss = 1.63145337e-06\n",
            "It 00500: Boundary Start loss = 1.42677068e-01\n",
            "It 00500: Boundary End loss = 1.35494298e-01\n",
            "It 00500: Boundary Bottom loss = 1.12959312e-04\n",
            "It 00500: loss = 1.86419786e+12\n",
            "\n",
            "It 00525: Train loss = 1.86419784e+12\n",
            "It 00525: Collocation loss = 1.83942310e+04\n",
            "It 00525: Initial loss = 1.58949863e-06\n",
            "It 00525: Boundary Start loss = 1.34699865e-01\n",
            "It 00525: Boundary End loss = 1.29031691e-01\n",
            "It 00525: Boundary Bottom loss = 1.10273439e-04\n",
            "It 00525: loss = 1.86419786e+12\n",
            "\n",
            "It 00550: Train loss = 1.86419784e+12\n",
            "It 00550: Collocation loss = 1.78071518e+04\n",
            "It 00550: Initial loss = 1.55641544e-06\n",
            "It 00550: Boundary Start loss = 1.27683611e-01\n",
            "It 00550: Boundary End loss = 1.23345657e-01\n",
            "It 00550: Boundary Bottom loss = 1.07717436e-04\n",
            "It 00550: loss = 1.86419786e+12\n",
            "\n",
            "It 00575: Train loss = 1.86419784e+12\n",
            "It 00575: Collocation loss = 1.72701614e+04\n",
            "It 00575: Initial loss = 1.53135908e-06\n",
            "It 00575: Boundary Start loss = 1.21527810e-01\n",
            "It 00575: Boundary End loss = 1.18350972e-01\n",
            "It 00575: Boundary Bottom loss = 1.05288413e-04\n",
            "It 00575: loss = 1.86419786e+12\n",
            "\n",
            "It 00600: Train loss = 1.86419784e+12\n",
            "It 00600: Collocation loss = 1.67780589e+04\n",
            "It 00600: Initial loss = 1.51348461e-06\n",
            "It 00600: Boundary Start loss = 1.16133309e-01\n",
            "It 00600: Boundary End loss = 1.13963794e-01\n",
            "It 00600: Boundary Bottom loss = 1.02982304e-04\n",
            "It 00600: loss = 1.86419786e+12\n",
            "\n",
            "It 00625: Train loss = 1.86419784e+12\n",
            "It 00625: Collocation loss = 1.63257196e+04\n",
            "It 00625: Initial loss = 1.50196376e-06\n",
            "It 00625: Boundary Start loss = 1.11404457e-01\n",
            "It 00625: Boundary End loss = 1.10103161e-01\n",
            "It 00625: Boundary Bottom loss = 1.00794650e-04\n",
            "It 00625: loss = 1.86419786e+12\n",
            "\n",
            "It 00650: Train loss = 1.86419784e+12\n",
            "It 00650: Collocation loss = 1.59082971e+04\n",
            "It 00650: Initial loss = 1.49599803e-06\n",
            "It 00650: Boundary Start loss = 1.07250715e-01\n",
            "It 00650: Boundary End loss = 1.06692778e-01\n",
            "It 00650: Boundary Bottom loss = 9.87200268e-05\n",
            "It 00650: loss = 1.86419786e+12\n",
            "\n",
            "It 00675: Train loss = 1.86419784e+12\n",
            "It 00675: Collocation loss = 1.55212210e+04\n",
            "It 00675: Initial loss = 1.49481932e-06\n",
            "It 00675: Boundary Start loss = 1.03588049e-01\n",
            "It 00675: Boundary End loss = 1.03662190e-01\n",
            "It 00675: Boundary Bottom loss = 9.67527073e-05\n",
            "It 00675: loss = 1.86419786e+12\n",
            "\n",
            "It 00700: Train loss = 1.86419784e+12\n",
            "It 00700: Collocation loss = 1.51603794e+04\n",
            "It 00700: Initial loss = 1.49770881e-06\n",
            "It 00700: Boundary Start loss = 1.00340091e-01\n",
            "It 00700: Boundary End loss = 1.00947894e-01\n",
            "It 00700: Boundary Bottom loss = 9.48861873e-05\n",
            "It 00700: loss = 1.86419786e+12\n",
            "\n",
            "It 00725: Train loss = 1.86419784e+12\n",
            "It 00725: Collocation loss = 1.48219894e+04\n",
            "It 00725: Initial loss = 1.50397395e-06\n",
            "It 00725: Boundary Start loss = 9.74385986e-02\n",
            "It 00725: Boundary End loss = 9.84937599e-02\n",
            "It 00725: Boundary Bottom loss = 9.31142482e-05\n",
            "It 00725: loss = 1.86419786e+12\n",
            "\n",
            "It 00750: Train loss = 1.86419784e+12\n",
            "It 00750: Collocation loss = 1.45027564e+04\n",
            "It 00750: Initial loss = 1.51299741e-06\n",
            "It 00750: Boundary Start loss = 9.48239786e-02\n",
            "It 00750: Boundary End loss = 9.62509738e-02\n",
            "It 00750: Boundary Bottom loss = 9.14303842e-05\n",
            "It 00750: loss = 1.86419786e+12\n",
            "\n",
            "It 00775: Train loss = 1.86419784e+12\n",
            "It 00775: Collocation loss = 1.41998195e+04\n",
            "It 00775: Initial loss = 1.52420316e-06\n",
            "It 00775: Boundary Start loss = 9.24448695e-02\n",
            "It 00775: Boundary End loss = 9.41782142e-02\n",
            "It 00775: Boundary Bottom loss = 8.98281185e-05\n",
            "It 00775: loss = 1.86419786e+12\n",
            "\n",
            "It 00800: Train loss = 1.86419784e+12\n",
            "It 00800: Collocation loss = 1.39107282e+04\n",
            "It 00800: Initial loss = 1.53707172e-06\n",
            "It 00800: Boundary Start loss = 9.02578739e-02\n",
            "It 00800: Boundary End loss = 9.22410290e-02\n",
            "It 00800: Boundary Bottom loss = 8.83009982e-05\n",
            "It 00800: loss = 1.86419786e+12\n",
            "\n",
            "It 00825: Train loss = 1.86419784e+12\n",
            "It 00825: Collocation loss = 1.36334518e+04\n",
            "It 00825: Initial loss = 1.55113194e-06\n",
            "It 00825: Boundary Start loss = 8.82268204e-02\n",
            "It 00825: Boundary End loss = 9.04113185e-02\n",
            "It 00825: Boundary Bottom loss = 8.68430346e-05\n",
            "It 00825: loss = 1.86419786e+12\n",
            "\n",
            "It 00850: Train loss = 1.86419784e+12\n",
            "It 00850: Collocation loss = 1.33662496e+04\n",
            "It 00850: Initial loss = 1.56597055e-06\n",
            "It 00850: Boundary Start loss = 8.63220818e-02\n",
            "It 00850: Boundary End loss = 8.86665164e-02\n",
            "It 00850: Boundary Bottom loss = 8.54482157e-05\n",
            "It 00850: loss = 1.86419786e+12\n",
            "\n",
            "It 00875: Train loss = 1.86419784e+12\n",
            "It 00875: Collocation loss = 1.31077538e+04\n",
            "It 00875: Initial loss = 1.58121557e-06\n",
            "It 00875: Boundary Start loss = 8.45196486e-02\n",
            "It 00875: Boundary End loss = 8.69889198e-02\n",
            "It 00875: Boundary Bottom loss = 8.41110742e-05\n",
            "It 00875: loss = 1.86419786e+12\n",
            "\n",
            "It 00900: Train loss = 1.86419784e+12\n",
            "It 00900: Collocation loss = 1.28567683e+04\n",
            "It 00900: Initial loss = 1.59655950e-06\n",
            "It 00900: Boundary Start loss = 8.28004341e-02\n",
            "It 00900: Boundary End loss = 8.53649066e-02\n",
            "It 00900: Boundary Bottom loss = 8.28265297e-05\n",
            "It 00900: loss = 1.86419786e+12\n",
            "\n",
            "It 00925: Train loss = 1.86419784e+12\n",
            "It 00925: Collocation loss = 1.26124573e+04\n",
            "It 00925: Initial loss = 1.61169595e-06\n",
            "It 00925: Boundary Start loss = 8.11491764e-02\n",
            "It 00925: Boundary End loss = 8.37842341e-02\n",
            "It 00925: Boundary Bottom loss = 8.15895941e-05\n",
            "It 00925: loss = 1.86419786e+12\n",
            "\n",
            "It 00950: Train loss = 1.86419784e+12\n",
            "It 00950: Collocation loss = 1.23740211e+04\n",
            "It 00950: Initial loss = 1.62639134e-06\n",
            "It 00950: Boundary Start loss = 7.95542055e-02\n",
            "It 00950: Boundary End loss = 8.22390743e-02\n",
            "It 00950: Boundary Bottom loss = 8.03963330e-05\n",
            "It 00950: loss = 1.86419786e+12\n",
            "\n",
            "It 00975: Train loss = 1.86419784e+12\n",
            "It 00975: Collocation loss = 1.21408889e+04\n",
            "It 00975: Initial loss = 1.64043700e-06\n",
            "It 00975: Boundary Start loss = 7.80062467e-02\n",
            "It 00975: Boundary End loss = 8.07239266e-02\n",
            "It 00975: Boundary Bottom loss = 7.92424985e-05\n",
            "It 00975: loss = 1.86419786e+12\n",
            "\n",
            "It 01000: Train loss = 1.86419784e+12\n",
            "It 01000: Collocation loss = 1.19125747e+04\n",
            "It 01000: Initial loss = 1.65365742e-06\n",
            "It 01000: Boundary Start loss = 7.64982652e-02\n",
            "It 01000: Boundary End loss = 7.92347485e-02\n",
            "It 01000: Boundary Bottom loss = 7.81244919e-05\n",
            "It 01000: loss = 1.86419786e+12\n",
            "\n",
            "\n",
            "Computation time: 322.37792205810547 seconds\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import explained_variance_score\n",
        "print(f\"Neural Network Explained Variance: { explained_variance_score(y, model.model(X)):.4f}\")"
      ],
      "metadata": {
        "id": "7mZIcSNibdRT",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "53db29db-ed15-412e-cfd7-68b2c07b3c63"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Neural Network Explained Variance: 0.0000\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### **$T_{model}(t)$ Visulatization**"
      ],
      "metadata": {
        "id": "cd7eSjEVcjX_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# fig = plt.figure(figsize=(15,15))\n",
        "# ax = fig.add_subplot(111, projection='3d')\n",
        "\n",
        "for i in range(0, 30):\n",
        "    aaaa = coordinates[:, 0:1]\n",
        "    bbbb = times[i][0]*np.ones((NUM_PARTICLES, 1))\n",
        "    \n",
        "    zzzz = (aaaa - (v*bbbb - 0.06))\n",
        "    cccc = np.hstack((coordinates, bbbb, zzzz))\n",
        "    dddd = model.model(tf.Variable(cccc)).numpy()\n",
        "    \n",
        "    TTTT = T_0 + dddd*np.exp(-(v*alpha*zzzz)/2)\n",
        "    # print(f\"Timestep : {i}\")\n",
        "    print(TTTT.reshape(-1))\n",
        "    # print(dddd.reshape(-1))\n",
        "    print(\"\\n\")\n",
        "    # ax.plot(coordinates[:, 0], \n",
        "    #         times[i][0]*np.ones(NUM_PARTICLES),\n",
        "    #         TTTT.reshape(-1))\n",
        "    \n",
        "    # tt = times[:DEPOSITION_TIME_STEP, :]\n",
        "    # xx = np.array([coordinates[i:i+1, :][0]]*tt.shape[0])\n",
        "    # zz = (xx - (v*tt - 0.06))\n",
        "    # TT = temperatures[:DEPOSITION_TIME_STEP, i:i+1]\n",
        "    # pp = (TT - T_0) / np.exp(-(v*alpha*zz)/2)\n",
        "    # ff = np.hstack((xx, tt, zz, pp, TT))\n",
        "\n",
        "# ax.view_init(30, 60)\n",
        "# plt.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c2b363d6-9bf6-4a6f-f777-1dc76da1915f",
        "id": "sEGKytk0cjYX"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[293.15190068 293.15024786 293.15003229 293.1500042  293.15000055\n",
            " 293.15000007 293.15000001 293.15       293.15       293.15\n",
            " 293.15       293.15       293.15       293.15       293.15\n",
            " 293.15       293.15       293.15       293.15       293.15\n",
            " 293.15       293.15       293.15       293.15       293.15      ]\n",
            "\n",
            "\n",
            "[293.15098431 293.15012304 293.15001534 293.15000191 293.15000024\n",
            " 293.15000003 293.15       293.15       293.15       293.15\n",
            " 293.15       293.15       293.15       293.15       293.15\n",
            " 293.15       293.15       293.15       293.15       293.15\n",
            " 293.15       293.15       293.15       293.15       293.15      ]\n",
            "\n",
            "\n",
            "[293.14790769 293.14970724 293.14995909 293.14999429 293.1499992\n",
            " 293.14999989 293.14999998 293.15       293.15       293.15\n",
            " 293.15       293.15       293.15       293.15       293.15\n",
            " 293.15       293.15       293.15       293.15       293.15\n",
            " 293.15       293.15       293.15       293.15       293.15      ]\n",
            "\n",
            "\n",
            "[293.14277277 293.14900924 293.14986418 293.14998138 293.14999745\n",
            " 293.14999965 293.14999995 293.14999999 293.15       293.15\n",
            " 293.15       293.15       293.15       293.15       293.15\n",
            " 293.15       293.15       293.15       293.15       293.15\n",
            " 293.15       293.15       293.15       293.15       293.15      ]\n",
            "\n",
            "\n",
            "[293.13523538 293.14797698 293.14972284 293.14996203 293.1499948\n",
            " 293.14999929 293.1499999  293.14999999 293.15       293.15\n",
            " 293.15       293.15       293.15       293.15       293.15\n",
            " 293.15       293.15       293.15       293.15       293.15\n",
            " 293.15       293.15       293.15       293.15       293.15      ]\n",
            "\n",
            "\n",
            "[293.12563778 293.14665418 293.14954062 293.14993694 293.14999135\n",
            " 293.14999881 293.14999984 293.14999998 293.15       293.15\n",
            " 293.15       293.15       293.15       293.15       293.15\n",
            " 293.15       293.15       293.15       293.15       293.15\n",
            " 293.15       293.15       293.15       293.15       293.15      ]\n",
            "\n",
            "\n",
            "[293.11924908 293.14573412 293.14940882 293.14991815 293.14998868\n",
            " 293.14999844 293.14999978 293.14999997 293.15       293.15\n",
            " 293.15       293.15       293.15       293.15       293.15\n",
            " 293.15       293.15       293.15       293.15       293.15\n",
            " 293.15       293.15       293.15       293.15       293.15      ]\n",
            "\n",
            "\n",
            "[293.13507484 293.14775005 293.14966491 293.14995059 293.14999277\n",
            " 293.14999895 293.14999985 293.14999998 293.15       293.15\n",
            " 293.15       293.15       293.15       293.15       293.15\n",
            " 293.15       293.15       293.15       293.15       293.15\n",
            " 293.15       293.15       293.15       293.15       293.15      ]\n",
            "\n",
            "\n",
            "[293.22695547 293.15991098 293.15127432 293.15016356 293.15002096\n",
            " 293.15000268 293.15000034 293.15000004 293.15000001 293.15\n",
            " 293.15       293.15       293.15       293.15       293.15\n",
            " 293.15       293.15       293.15       293.15       293.15\n",
            " 293.15       293.15       293.15       293.15       293.15      ]\n",
            "\n",
            "\n",
            "[293.53300929 293.20074451 293.15672264 293.15089058 293.15011798\n",
            " 293.15001563 293.15000207 293.15000027 293.15000004 293.15\n",
            " 293.15       293.15       293.15       293.15       293.15\n",
            " 293.15       293.15       293.15       293.15       293.15\n",
            " 293.15       293.15       293.15       293.15       293.15      ]\n",
            "\n",
            "\n",
            "[294.38612443 293.31496453 293.17201656 293.15293863 293.15039227\n",
            " 293.15005237 293.15000699 293.15000093 293.15000012 293.15000002\n",
            " 293.15       293.15       293.15       293.15       293.15\n",
            " 293.15       293.15       293.15       293.15       293.15\n",
            " 293.15       293.15       293.15       293.15       293.15      ]\n",
            "\n",
            "\n",
            "[296.55403456 293.60579203 293.21103566 293.15817429 293.15109489\n",
            " 293.15014667 293.15001965 293.15000263 293.15000035 293.15000005\n",
            " 293.15000001 293.15       293.15       293.15       293.15\n",
            " 293.15       293.15       293.15       293.15       293.15\n",
            " 293.15       293.15       293.15       293.15       293.15      ]\n",
            "\n",
            "\n",
            "[301.74781427 294.30345068 293.30476034 293.17076702 293.15278706\n",
            " 293.1503741  293.15005022 293.15000674 293.15000091 293.15000012\n",
            " 293.15000002 293.15       293.15       293.15       293.15\n",
            " 293.15       293.15       293.15       293.15       293.15\n",
            " 293.15       293.15       293.15       293.15       293.15      ]\n",
            "\n",
            "\n",
            "[313.67280087 295.90680467 293.5203642  293.19976332 293.1566873\n",
            " 293.15089879 293.15012082 293.15001624 293.15000218 293.15000029\n",
            " 293.15000004 293.15000001 293.15       293.15       293.15\n",
            " 293.15       293.15       293.15       293.15       293.15\n",
            " 293.15       293.15       293.15       293.15       293.15      ]\n",
            "\n",
            "\n",
            "[340.14654791 299.46896727 293.9997362  293.26428348 293.16537261\n",
            " 293.15206814 293.15027828 293.15003745 293.15000504 293.15000068\n",
            " 293.15000009 293.15000001 293.15       293.15       293.15\n",
            " 293.15       293.15       293.15       293.15       293.15\n",
            " 293.15       293.15       293.15       293.15       293.15      ]\n",
            "\n",
            "\n",
            "[397.25037888 307.15750468 295.03509107 293.40372909 293.18415685\n",
            " 293.15459895 293.15061932 293.15008342 293.15001124 293.15000151\n",
            " 293.1500002  293.15000003 293.15       293.15       293.15\n",
            " 293.15       293.15       293.15       293.15       293.15\n",
            " 293.15       293.15       293.15       293.15       293.15      ]\n",
            "\n",
            "\n",
            "[517.20328064 323.3177849  297.21261228 293.69719281 293.22371428\n",
            " 293.15993212 293.15133849 293.15018042 293.15002432 293.15000328\n",
            " 293.15000044 293.15000006 293.15000001 293.15       293.15\n",
            " 293.15       293.15       293.15       293.15       293.15\n",
            " 293.15       293.15       293.15       293.15       293.15      ]\n",
            "\n",
            "\n",
            "[762.67310138 356.40781807 301.67413111 294.29886214 293.30487123\n",
            " 293.1708815  293.15281607 293.15037986 293.15005125 293.15000692\n",
            " 293.15000093 293.15000013 293.15000002 293.15       293.15\n",
            " 293.15       293.15       293.15       293.15       293.15\n",
            " 293.15       293.15       293.15       293.15       293.15      ]\n",
            "\n",
            "\n",
            "[1251.25059466  422.31279841  310.56623062  295.4989001   293.46686318\n",
            "  293.19275422  293.15577018  293.15077894  293.15010518  293.1500142\n",
            "  293.15000192  293.15000026  293.15000003  293.15        293.15\n",
            "  293.15        293.15        293.15        293.15        293.15\n",
            "  293.15        293.15        293.15        293.15        293.15      ]\n",
            "\n",
            "\n",
            "[2193.30476884  549.48812622  327.73945007  297.81856816  293.78028447\n",
            "  293.23511488  293.16149723  293.15155347  293.15020996  293.15002838\n",
            "  293.15000384  293.15000052  293.15000007  293.15000001  293.15\n",
            "  293.15        293.15        293.15        293.15        293.15\n",
            "  293.15        293.15        293.15        293.15        293.15      ]\n",
            "\n",
            "\n",
            "[3939.41232936  785.4543021   359.63866556  302.13241976  294.36387546\n",
            "  293.31409415  293.17218979  293.15300163  293.15040617  293.15005497\n",
            "  293.15000744  293.15000101  293.15000014  293.15000002  293.15\n",
            "  293.15        293.15        293.15        293.15        293.15\n",
            "  293.15        293.15        293.15        293.15        293.15      ]\n",
            "\n",
            "\n",
            "[7005.4407317  1200.42970077  415.82948087  309.74458783  295.39557756\n",
            "  293.45399027  293.1911684   293.15557755  293.15075596  293.15010248\n",
            "  293.15001389  293.15000188  293.15000026  293.15000003  293.15\n",
            "  293.15        293.15        293.15        293.15        293.15\n",
            "  293.15        293.15        293.15        293.15        293.15      ]\n",
            "\n",
            "\n",
            "[11954.69190265  1872.05968311   507.02920189   322.13631081\n",
            "   297.0803678    293.68320179   293.2223719    293.1598281\n",
            "   293.15133534   293.15018148   293.15002466   293.15000335\n",
            "   293.15000046   293.15000006   293.15000001   293.15\n",
            "   293.15         293.15         293.15         293.15\n",
            "   293.15         293.15         293.15         293.15\n",
            "   293.15      ]\n",
            "\n",
            "\n",
            "[18765.1878798   2801.62197568   634.02775783   339.50369716\n",
            "   299.45764055   294.00890688   293.26703635   293.16595839\n",
            "   293.15217745   293.15029721   293.15004056   293.15000553\n",
            "   293.15000075   293.1500001    293.15000001   293.15\n",
            "   293.15         293.15         293.15         293.15\n",
            "   293.15         293.15         293.15         293.15\n",
            "   293.15      ]\n",
            "\n",
            "\n",
            "[24640.62743342  3622.54888048   748.91681608   355.60627366\n",
            "   301.71753325   294.32644131   293.31169869   293.17224592\n",
            "   293.15306328   293.15042198   293.1500581    293.150008\n",
            "   293.1500011    293.15000015   293.15000002   293.15\n",
            "   293.15         293.15         293.15         293.15\n",
            "   293.15         293.15         293.15         293.15\n",
            "   293.15      ]\n",
            "\n",
            "\n",
            "[17511.59886955  2733.04291009   639.41183216   342.35236756\n",
            "   300.14862944   294.14630418   293.29191805   293.17022429\n",
            "   293.1528829    293.15041059   293.15005832   293.15000826\n",
            "   293.15000117   293.15000016   293.15000002   293.15\n",
            "   293.15         293.15         293.15         293.15\n",
            "   293.15         293.15         293.15         293.15\n",
            "   293.15      ]\n",
            "\n",
            "\n",
            "[-41775.35948895  -5084.14332403   -389.0297303     207.37428866\n",
            "    282.47990764    291.84012219    292.99186514    293.13132303\n",
            "    293.1478594     293.14976435    293.1499754     293.14999765\n",
            "    293.14999981    293.14999999    293.15          293.15\n",
            "    293.15          293.15          293.15          293.15\n",
            "    293.15          293.15          293.15          293.15\n",
            "    293.15      ]\n",
            "\n",
            "\n",
            "[-2.65890466e+05 -3.48714573e+04 -4.34320724e+03 -3.16844203e+02\n",
            "  2.13079342e+02  2.82665944e+02  2.91781047e+02  2.92971791e+02\n",
            "  2.93126879e+02  2.93147010e+02  2.93149614e+02  2.93149950e+02\n",
            "  2.93149994e+02  2.93149999e+02  2.93150000e+02  2.93150000e+02\n",
            "  2.93150000e+02  2.93150000e+02  2.93150000e+02  2.93150000e+02\n",
            "  2.93150000e+02  2.93150000e+02  2.93150000e+02  2.93150000e+02\n",
            "  2.93150000e+02]\n",
            "\n",
            "\n",
            "[-9.57929403e+05 -1.27138224e+05 -1.66338572e+04 -1.95252727e+03\n",
            " -4.38918694e+00  2.53782910e+02  2.87949164e+02  2.92464002e+02\n",
            "  2.93059661e+02  2.93138121e+02  2.93148439e+02  2.93149795e+02\n",
            "  2.93149973e+02  2.93149996e+02  2.93150000e+02  2.93150000e+02\n",
            "  2.93150000e+02  2.93150000e+02  2.93150000e+02  2.93150000e+02\n",
            "  2.93150000e+02  2.93150000e+02  2.93150000e+02  2.93150000e+02\n",
            "  2.93150000e+02]\n",
            "\n",
            "\n",
            "[-2.89819635e+06 -3.86239209e+05 -5.12091566e+04 -6.56291811e+03\n",
            " -6.18690541e+02  1.71988820e+02  2.77066222e+02  2.91017114e+02\n",
            "  2.92867463e+02  2.93112611e+02  2.93145054e+02  2.93149346e+02\n",
            "  2.93149914e+02  2.93149989e+02  2.93149998e+02  2.93150000e+02\n",
            "  2.93150000e+02  2.93150000e+02  2.93150000e+02  2.93150000e+02\n",
            "  2.93150000e+02  2.93150000e+02  2.93150000e+02  2.93150000e+02\n",
            "  2.93150000e+02]\n",
            "\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "zEXSler6Sg3l"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}